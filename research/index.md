---
layout: default
title: Research Projects
projects:
  - link: dialport/
    name: An Exciting project
    summary: This will never work.
  - link: distraction/
    name: An Exciting project
    summary: This will never work.
---

Our research mainly focuses on spoken dialog systems and conversational interfaces for more natural and efficient human-computer interaction. Specifically, we have several ongoing research projects:

### DialPort: Enabling Spoken Dialog Research with Real Data

Innovation in spoken dialog technology requires a shared platform where new ideas can flourish, new dialog problems can come to the surface and communities can form to leverage different parts of the solution for better spoken dialog systems.

DialPort will allow for new application ideas and newly available technologies to be shared which will in turn attract real users, creating real data. The creation of this platform is the goal of DialPort. Therefore, we need a community website and portal that can help the community to create these platforms for future applications and provide a stream of real users. DialPort will work with the spoken dialog community to create and share real user applications that serve as data streams and research platforms.

Read more about it and **talk to our agent Skylar [here][dialport]**.

[dialport]: https://skylar.speech.cs.cmu.edu/master/PortalSite/

### Multi-modal Distraction Detection

Distracted Driving continues to be a cause of traffic accidents despite prevailing legislation. The goal of this project is to automatically determine when the driver is becoming distracted. This information can be sent to a warning system in a car or can be used to help shut down the distracting activity. While we are able to detect distraction fairly reliably using such information as speech, gas pedal and brake use, and steering wheel trajectory, the use of automatic detection of head movement will make the distraction detector more robust. In many cases, the driver turns their head to either talk to a passenger or, more frequently, look at a smart device. In this project, we will gather data in a driving simulator from 50 subjects who are first asked to drive the course and then asked to watch the recording of their driving and tell us where they were distracted. They will use their own smart devices to listen to and dictate email. The conditions will vary with email of differing degrees of cognitive load, road conditions of varying difficulty and varying need to look at the smart device. The resulting database will be used to train and test a new and robust distraction detector.

### The REAL Challenge

The REAL Challenge took place for the first time in 2014, with a long term goal of creating streams of real data that the research community can use, by fostering the creation of systems that are capable of attracting real users.

A past video presentation could be found [here][real].

[real]: https://www.youtube.com/watch?v=Y9fJDON8b-c

## Past Research Projects

### Let's Go!: A Spoken Dialog System For The General Public

Let's Go! is building a spoken dialog system that can be used by the general public. While there has been success in building spoken dialog systems that can interact well with people, these systems often work only for a limited group of people. The system we are developing for Let's Go! is designed to work with a much wider population, including groups that typically have trouble interacting with dialog systems, such as non-native English speakers and the elderly. Let's Go! works in the domain of bus information for Pittsburgh's Port Authority Transit bus system, providing a telephone-based interface to access bus schedules and route information.

Read more about it [here][letsgo].

**Let's Go has been integrated to DialPort, talk to it [here][dialport]!**

[letsgo]: http://www.speech.cs.cmu.edu/letsgo/









